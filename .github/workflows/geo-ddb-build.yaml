name: Create Geographical Data in DuckDB
on: workflow_dispatch

env:
  GEO_DIR: geo-data
  DDB_NAME: geo-data.db
  RCLONE_CFG_NAME: rg
  S3_BUCKET: rowerowegminy.pl
  GML_PAK_URL: https://eu2.contabostorage.com/9556be5764414357ae3184b95da10055:rowerowegminy.pl/gml_pak.zip
  ARTIFACT_NAME: geo-ddb
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: install Rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash
      - name: Set up S3cmd cli tool
        uses: s3-actions/s3cmd@v1.9.0
        with:
          provider: aws # default is linode
          region: 'eu-central-1'
          access_key: ${{ secrets.S3_ACCESS_KEY }}
          secret_key: ${{ secrets.S3_SECRET_KEY }}
      - name: Download GML files
        run: |
          wget $GML_PAK_URL

      - name: Unzip GML files
        run: |
          mkdir -p $GEO_DIR
          unzip gml_pak.zip -d $GEO_DIR

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Setup PDM
        uses: pdm-project/setup-pdm@v4

      - name: Install dependencies
        run: pdm install
      
      - name: Create GeoJSON files
        run: |
          # Find all .gml files and process each
          find $GEO_DIR -name "*.gml" -type f -print0 | xargs -0 -I {} pdm run rg-geo preprocess --path {}
      
      - name: Create DuckDB database
        run: pdm run rg-geo create-ddb --json_dir $GEO_DIR --db_path $DDB_NAME

      - uses: actions/upload-artifact@v4
        with:
          name: ${{ env.ARTIFACT_NAME }}  # From env
          path: ${{ env.DDB_NAME }}       # From env
      
      - name: Create Rclone config
        run: |
          cat << 'EOF' > rclone.conf
          ${{ secrets.RCLONE_S3_CFG }}
          EOF
          
      
      - name: Upload DuckDB database to S3
        run: rclone --config rclone.conf copy $DDB_NAME $RCLONE_CFG_NAME:$S3_BUCKET

